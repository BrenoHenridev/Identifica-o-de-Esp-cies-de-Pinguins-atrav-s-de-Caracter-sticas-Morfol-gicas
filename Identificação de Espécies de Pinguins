# -*- coding: utf-8 -*-
"""Projeto Final - Classificação de Pinguins.ipynb

Automatically generated by Colaboratory.

Original file is located at:
    https://colab.research.google.com/drive/1abc1234xyz
"""

## Importação de Bibliotecas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Configuração de Visualização
sns.set(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
pd.set_option('display.max_columns', 50)

## 1. Coleta e Pré-Processamento de Dados
# Carregar dados (substitua pelo caminho real do seu arquivo)
# df = pd.read_csv('penguins.csv')
# Dados de exemplo para demonstração:
data = {
    'species': ['Adelie', 'Adelie', 'Gentoo', 'Chinstrap', 'Gentoo'],
    'island': ['Torgersen', 'Torgersen', 'Biscoe', 'Dream', 'Biscoe'],
    'bill_length_mm': [39.1, 39.5, 45.1, 46.5, 47.3],
    'bill_depth_mm': [18.7, 17.4, 14.2, 17.9, 13.8],
    'flipper_length_mm': [181, 186, 210, 215, 208],
    'body_mass_g': [3750, 3800, 5200, 5400, 5100],
    'sex': ['Male', 'Female', 'Male', 'Female', 'Male']
}
df = pd.DataFrame(data)

# Pré-processamento
def preprocess_data(df):
    # 1. Tratamento de valores nulos
    df = df.dropna()
    
    # 2. Codificação de variáveis categóricas
    df = pd.get_dummies(df, columns=['island', 'sex'])
    
    # 3. Separação em features e target
    X = df.drop('species', axis=1)
    y = df['species']
    
    # 4. Padronização das variáveis numéricas
    numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
    scaler = StandardScaler()
    X[numeric_cols] = scaler.fit_transform(X[numeric_cols])
    
    return X, y, scaler

X, y, scaler = preprocess_data(df)

## 2. Modelagem Preditiva
# Divisão treino-teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Treinamento do modelo
model = DecisionTreeClassifier(max_depth=3, random_state=42)
model.fit(X_train, y_train)

# Avaliação
y_pred = model.predict(X_test)
print(f"Acurácia: {accuracy_score(y_test, y_pred):.2%}")
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred))

## 3. Visualização dos Resultados
# Matriz de Confusão
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), 
            annot=True, fmt='d', 
            cmap='Blues',
            xticklabels=model.classes_,
            yticklabels=model.classes_)
plt.title('Matriz de Confusão')
plt.show()

# Importância das Features
plt.figure(figsize=(10, 5))
pd.Series(model.feature_importances_, index=X.columns).sort_values().plot.barh()
plt.title('Importância das Features na Árvore de Decisão')
plt.show()

## 4. Agrupamento com K-Means
# Redução de dimensionalidade para visualização
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X[numeric_cols])

# K-Means
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_pca)

# Visualização
plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette='viridis', s=100)
plt.title('Agrupamento de Pinguins (K-Means com PCA)')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.show()

## 5. Predição para Novos Dados
def predict_new_sample(sample_data):
    """Função para prever novas amostras"""
    # Pré-processamento
    sample_df = pd.DataFrame([sample_data])
    sample_df = pd.get_dummies(sample_df)
    
    # Garantir todas as colunas do modelo
    for col in X.columns:
        if col not in sample_df.columns:
            sample_df[col] = 0
    
    # Reordenar colunas
    sample_df = sample_df[X.columns]
    
    # Padronização
    sample_df[numeric_cols] = scaler.transform(sample_df[numeric_cols])
    
    # Predição
    prediction = model.predict(sample_df)
    probabilities = model.predict_proba(sample_df)
    
    return prediction[0], probabilities

# Exemplo de uso:
sample = {
    'island': 'Biscoe',
    'bill_length_mm': 38.2,
    'bill_depth_mm': 18.1,
    'flipper_length_mm': 185.0,
    'body_mass_g': 3950.0,
    'sex': 'Male'
}

species, prob = predict_new_sample(sample)
print(f"\nPredição para nova amostra: {species}")
print(f"Probabilidades: {dict(zip(model.classes_, prob[0]))}")
